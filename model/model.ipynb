{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.datasets import load_files\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from gensim.models import Word2Vec, FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2200"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"../data/news_script_individual-200/\"\n",
    "news_list = sorted(os.listdir(data_path))\n",
    "len(news_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dictionary(eng_sentence):\n",
    "    dictionary = {}\n",
    "    for sent in eng_sentence:\n",
    "        pos_tags = nltk.pos_tag(nltk.word_tokenize(sent))\n",
    "        for tag in pos_tags:\n",
    "            value = tag[0]\n",
    "            pos = tag[1]\n",
    "            dictionary[value] = pos\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "def text_preprocess(text):\n",
    "    # Remove all the special characters\n",
    "    document = re.sub(r'\\W', ' ', text)\n",
    "    \n",
    "    document = document.replace('.', '')\n",
    "    \n",
    "    document = re.sub('[^a-zA]',' ',document).strip()\n",
    "    \n",
    "    # Converting to Lowercase\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "    english_stops = set(stopwords.words('english'))\n",
    "    document = [word for word in document if word not in english_stops]\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = [word for word in document if len(word) > 1]\n",
    "    document = [word for word in document if word.isalpha()]\n",
    "    pos_dict = build_dictionary(document)\n",
    "    document = [n for n, tag in pos_dict.items() if tag in [\"NN\",\"NNP\"] ]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    return document    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = []\n",
    "\n",
    "for i in range(len(news_list)):\n",
    "    f = open(data_path + news_list[i], 'r', encoding='UTF-8')\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tmp = text_preprocess(line).split()\n",
    "        if len(tmp) > 0:\n",
    "            text.append(text_preprocess(line).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.1 s\n"
     ]
    }
   ],
   "source": [
    "time Skip_gram_model = Word2Vec(text, size=16, window=3, min_count=1,  workers=1, sg=1, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "time Cbow_model = Word2Vec(text, size=16, window=3, min_count=1,  workers=1, sg=0, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Skip_gram_model.wv.vocab.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cbow_model.wv.most_similar(\"blackpink\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Skip_gram_model.wv.most_similar(\"singe\", topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0mSkip_gram_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Compute cosine distance between two words.\n",
       "Calculate 1 - :meth:`~gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similarity`.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "w1 : str\n",
       "    Input word.\n",
       "w2 : str\n",
       "    Input word.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "float\n",
       "    Distance between `w1` and `w2`.\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\users\\82109\\anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?Skip_gram_model.wv.distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_euc_dist(w1, w2, model=Skip_gram_model):\n",
    "    w1_vector, w2_vector = model.wv.get_vector(w1), model.wv.get_vector(w2)\n",
    "    print(f\"{w1} <--> {w2}\")\n",
    "    print('Euclidean: ', euclidean_distances(w1_vector.reshape(1,16), w2_vector.reshape(1,16))[0][0])\n",
    "    print('Cosine   : ', model.wv.distance(w1,w2))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kpop <--> idol\n",
      "Euclidean:  2.7254503\n",
      "Cosine   :  0.5781855583190918\n",
      "--------------------------------------------------\n",
      "dynamite <--> idol\n",
      "Euclidean:  2.2868202\n",
      "Cosine   :  0.3212130069732666\n",
      "--------------------------------------------------\n",
      "dynamite <--> song\n",
      "Euclidean:  2.327134\n",
      "Cosine   :  0.19012415409088135\n",
      "--------------------------------------------------\n",
      "dynamite <--> kpop\n",
      "Euclidean:  1.2445022\n",
      "Cosine   :  0.22412264347076416\n",
      "--------------------------------------------------\n",
      "blackpink <--> idol\n",
      "Euclidean:  2.3498466\n",
      "Cosine   :  0.3392786383628845\n",
      "--------------------------------------------------\n",
      "blackpink <--> song\n",
      "Euclidean:  2.3747857\n",
      "Cosine   :  0.17819619178771973\n",
      "--------------------------------------------------\n",
      "blackpink <--> kpop\n",
      "Euclidean:  1.2773558\n",
      "Cosine   :  0.22552794218063354\n",
      "--------------------------------------------------\n",
      "exo <--> idol\n",
      "Euclidean:  2.4998212\n",
      "Cosine   :  0.4068801999092102\n",
      "--------------------------------------------------\n",
      "exo <--> song\n",
      "Euclidean:  2.7079272\n",
      "Cosine   :  0.3677358031272888\n",
      "--------------------------------------------------\n",
      "exo <--> kpop\n",
      "Euclidean:  1.3530529\n",
      "Cosine   :  0.2222130298614502\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_cos_euc_dist(\"kpop\", \"idol\")\n",
    "get_cos_euc_dist(\"dynamite\", \"idol\")\n",
    "get_cos_euc_dist(\"dynamite\", \"song\")\n",
    "get_cos_euc_dist(\"dynamite\", \"kpop\")\n",
    "get_cos_euc_dist(\"blackpink\", \"idol\")\n",
    "get_cos_euc_dist(\"blackpink\", \"song\")\n",
    "get_cos_euc_dist(\"blackpink\", \"kpop\")\n",
    "get_cos_euc_dist(\"exo\", \"idol\")\n",
    "get_cos_euc_dist(\"exo\", \"song\")\n",
    "get_cos_euc_dist(\"exo\", \"kpop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_euc_dist2(w1, w2, model=Cbow_model):\n",
    "    w1_vector, w2_vector = model.wv.get_vector(w1), model.wv.get_vector(w2)\n",
    "    print(f\"{w1} <--> {w2}\")\n",
    "    print('Euclidean: ', euclidean_distances(w1_vector.reshape(1,16), w2_vector.reshape(1,16))[0][0])\n",
    "    print('Cosine   : ', model.wv.distance(w1,w2))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kpop <--> idol\n",
      "Euclidean:  5.747503\n",
      "Cosine   :  0.5080408453941345\n",
      "--------------------------------------------------\n",
      "dynamite <--> idol\n",
      "Euclidean:  6.4452796\n",
      "Cosine   :  0.5170215368270874\n",
      "--------------------------------------------------\n",
      "dynamite <--> song\n",
      "Euclidean:  7.8626\n",
      "Cosine   :  0.34231799840927124\n",
      "--------------------------------------------------\n",
      "dynamite <--> kpop\n",
      "Euclidean:  3.1474574\n",
      "Cosine   :  0.2638216018676758\n",
      "--------------------------------------------------\n",
      "blackpink <--> idol\n",
      "Euclidean:  6.48288\n",
      "Cosine   :  0.5280620753765106\n",
      "--------------------------------------------------\n",
      "blackpink <--> song\n",
      "Euclidean:  7.904689\n",
      "Cosine   :  0.31452876329421997\n",
      "--------------------------------------------------\n",
      "blackpink <--> kpop\n",
      "Euclidean:  3.1659849\n",
      "Cosine   :  0.1345774531364441\n",
      "--------------------------------------------------\n",
      "exo <--> idol\n",
      "Euclidean:  6.3987827\n",
      "Cosine   :  0.4781457185745239\n",
      "--------------------------------------------------\n",
      "exo <--> song\n",
      "Euclidean:  7.8824363\n",
      "Cosine   :  0.4955836534500122\n",
      "--------------------------------------------------\n",
      "exo <--> kpop\n",
      "Euclidean:  2.9968219\n",
      "Cosine   :  0.032253384590148926\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "get_cos_euc_dist2(\"kpop\", \"idol\")\n",
    "get_cos_euc_dist2(\"dynamite\", \"idol\")\n",
    "get_cos_euc_dist2(\"dynamite\", \"song\")\n",
    "get_cos_euc_dist2(\"dynamite\", \"kpop\")\n",
    "get_cos_euc_dist2(\"blackpink\", \"idol\")\n",
    "get_cos_euc_dist2(\"blackpink\", \"song\")\n",
    "get_cos_euc_dist2(\"blackpink\", \"kpop\")\n",
    "get_cos_euc_dist2(\"exo\", \"idol\")\n",
    "get_cos_euc_dist2(\"exo\", \"song\")\n",
    "get_cos_euc_dist2(\"exo\", \"kpop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 단어의 비슷한 단어 들의 거리 비교\n",
    "def get_top_similar_dist(word, model):\n",
    "    for word2, dist in model.wv.most_similar(word,topn=10):\n",
    "        get_cos_euc_dist(word, word2, model=model)"
   ]
  },
  {
      "cell_type": "code",
      "metadata": {
        "id": "MF2PbCVOKg6J"
      },
      "source": [
        "def plot_2d_graph(vocabs, xs, ys):\n",
        "  plt.figure(figsize=(10, 8))\n",
        "  plt.scatter(xs, ys, marker='o')\n",
        "  for i,v in enumerate(vocabs):\n",
        "    plt.annotate(v, xy=(xs[i], ys[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul7FUEIqL9_d"
      },
      "source": [
        "Skip_vectors = Skip_gram_model.wv\r\n",
        "Cbow_vectors = Cbow_model.wv\r\n",
        "\r\n",
        "Skip_vocabs = Skip_vectors.vocab.keys()\r\n",
        "Cbow_vocabs = Cbow_vectors.vocab.keys()\r\n",
        "Skip_vectors_list = [Skip_vectors[v] for v in Skip_vocabs]\r\n",
        "Cbow_vectors_list = [Cbow_vectors[v] for v in Cbow_vocabs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_OokbOOK7ZY"
      },
      "source": [
        "from sklearn.decomposition import PCA\r\n",
        "pca = PCA(n_components=2)\r\n",
        "xys = pca.fit_transform(Skip_vectors_list[:15])\r\n",
        "xs = xys[:,0]\r\n",
        "ys = xys[:,1]\r\n",
        "\r\n",
        "plot_2d_graph(Skip_vocabs, xs, ys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GU-BfVeaXILi"
      },
      "source": [
        "from sklearn.decomposition import PCA\r\n",
        "pca = PCA(n_components=2)\r\n",
        "xys = pca.fit_transform(Cbow_vectors_list[:15])\r\n",
        "xs = xys[:,0]\r\n",
        "ys = xys[:,1]\r\n",
        "\r\n",
        "plot_2d_graph(Cbow_vocabs, xs, ys)"
      ],
      "execution_count": null,
      "outputs": []
    }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
